{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9nswTThvVj0"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10421,
     "status": "ok",
     "timestamp": 1674465161457,
     "user": {
      "displayName": "Fouad",
      "userId": "18387314049650182816"
     },
     "user_tz": -60
    },
    "id": "9S_Cbn5wpSyB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d_points(d,n):\n",
    "    points=[]\n",
    "    tetas = np.arange(0,2*np.pi,2*np.pi/n)\n",
    "    for t in tetas:\n",
    "        points.append((d*np.cos(t),d*np.sin(t)))\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_points(ri,re,n):\n",
    "    points=[]\n",
    "    tetas = np.arange(0,2*np.pi,2*np.pi/n)\n",
    "    for t in tetas:\n",
    "        points.append((ri*np.cos(t),ri*np.sin(t)))\n",
    "    for t in tetas:\n",
    "         points.append((re*np.cos(t),re*np.sin(t)))\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCOZWsVJZgDN",
    "tags": []
   },
   "source": [
    "# Marginal Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cylinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_max = 200\n",
    "re_min = 10\n",
    "ri_max = re_max-5\n",
    "ri_min = re_min-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-FcHt_Lq8G3o"
   },
   "outputs": [],
   "source": [
    "def generate_marginal_cylinder(n):\n",
    "    re = np.random.uniform(re_min,re_max,n)\n",
    "    ri = []\n",
    "    for r in re:\n",
    "        ri.append(np.random.uniform(ri_min,r-5))\n",
    "    ri = np.array(ri)\n",
    "    \n",
    "    ri_ = np.random.uniform(ri_min,ri_max,n)\n",
    "    re_ = []\n",
    "    for r in ri_:\n",
    "        re_.append(np.random.uniform(r+5,re_max))\n",
    "    re_ = np.array(re_)\n",
    "    \n",
    "    re = np.concatenate((re,re_),0)\n",
    "    ri = np.concatenate((ri,ri_),0)\n",
    "\n",
    "    return ri, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_min = 1\n",
    "d_max = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_marginal_density(n):\n",
    "    return np.random.uniform(d_min,d_max,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_save_path = os.path.join(os.path.abspath('..'),\"src/dataset/marginals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cylinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:04<00:00, 4957.87it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4956.59it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4925.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for stage in ['train', 'val', 'test']:\n",
    "    save_path = os.path.join(marginal_save_path, 'cylinders', stage)\n",
    "    \n",
    "    # Create the directories if they don't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    dataset = []\n",
    "    n = 20000 if stage == 'train' else (5000 if stage == 'test' else 1000)\n",
    "    ri, re = generate_marginal_cylinder(n // 2)\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        dataset.append(get_c_points(ri[i], re[i], 30))\n",
    "    \n",
    "    dataset = np.array(dataset)\n",
    "    save_path = os.path.join(save_path, \"cylinders\")\n",
    "    \n",
    "    # Save the dataset\n",
    "    np.save(save_path, dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:02<00:00, 9451.15it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8786.40it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 9316.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for stage in ['train', 'val', 'test']:\n",
    "    save_path = os.path.join(marginal_save_path, 'densities', stage)\n",
    "    \n",
    "    # Create the directories if they don't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    dataset = []\n",
    "    n = 20000 if stage == 'train' else (5000 if stage == 'test' else 1000)\n",
    "    d = generate_marginal_density(n)\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        dataset.append(get_d_points(d[i], 30))\n",
    "    \n",
    "    dataset = np.array(dataset)\n",
    "    save_path = os.path.join(save_path, \"densities\")\n",
    "    \n",
    "    # Save the dataset\n",
    "    np.save(save_path, dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Meta Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1_max = 100\n",
    "re1_min = 20\n",
    "ri1_max = re2_max = re1_max-5\n",
    "ri1_min = re2_min = re1_min-5\n",
    "ri2_max = re2_max-5\n",
    "ri2_min = re2_min-5\n",
    "d_min = 1\n",
    "d_max = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "radii|value\n",
    "----|----\n",
    "re1_max | 100\n",
    "re1_min | 20\n",
    "ri1_max / re2_max | 95\n",
    "ri1_min / re2_min | 15\n",
    "ri2_max | 90\n",
    "ri2_min | 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gneration functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1674465701261,
     "user": {
      "displayName": "Fouad",
      "userId": "18387314049650182816"
     },
     "user_tz": -60
    },
    "id": "1dIEWNtTYx5F"
   },
   "outputs": [],
   "source": [
    "def generate(n):\n",
    "    \n",
    "    # Radii generation\n",
    "    \n",
    "    # We generate cylinder radii by splitting the total number of radii into three equal parts.\n",
    "    # For each part, we start by generating one of the three radii (r_ext1, r_int1, or r_int2) uniformly at random.\n",
    "    # The other two radii are generated conditionally based on the first radii, following the rules detailed in the paper's appendix.\n",
    "    \n",
    "\n",
    "    # 1/3 of the cases: Generate r_ext1 first\n",
    "    re1 = np.random.uniform(re1_min,re1_max,(n//3,1))#100\n",
    "    ri1 = []\n",
    "    for r in re1:\n",
    "        ri1.append(np.random.uniform(ri1_min,r-5))\n",
    "    ri1 = np.array(ri1)\n",
    "    ri1 = np.where(ri1>re1-5,re1-5,ri1)\n",
    "\n",
    "    re2 = np.copy(ri1)\n",
    "    ri2 = []\n",
    "    for r in re2:\n",
    "        ri2.append(np.random.uniform(ri2_min,r-5))\n",
    "    ri2 = np.array(ri2)\n",
    "    ri2 = np.where(ri2>re2-5,re2-5,ri2)\n",
    "\n",
    "    # 1/3 of the cases: Generate r_int1 first\n",
    "    ri1_ = np.random.uniform(ri1_min,ri1_max,(n//3,1))#np.random.normal(70,10,(n,1))\n",
    "    re1_ = []\n",
    "    for r in ri1_:\n",
    "        re1_.append(np.random.uniform(r+5,re1_max))\n",
    "    re1_ = np.array(re1_)\n",
    "    re1_ = np.where(re1_<ri1_+5,ri1_+5,re1_)\n",
    "    re2_ = np.copy(ri1_)\n",
    "    ri2_ = []\n",
    "    for r in re2_:\n",
    "        ri2_.append(np.random.uniform(ri2_min,r-5))\n",
    "    ri2_ = np.array(ri2_)\n",
    "    ri2_ = np.where(ri2_>re2_-5,re2_-5,ri2_)\n",
    "\n",
    "    # 1/3 of the cases: Generate r_int2 first\n",
    "    ri2__ = np.random.uniform(ri2_min,ri2_max,(n//3,1))\n",
    "    re2__ = []\n",
    "    for r in ri2__:\n",
    "        re2__.append(np.random.uniform(r+5,re2_max))\n",
    "    re2__ = np.array(re2__)\n",
    "    re2__ = np.where(re2__<ri2__+5,ri2__+5,re2__)\n",
    "    ri1__ = np.copy(re2__)\n",
    "    re1__ = []\n",
    "    for r in ri1__:\n",
    "        re1__.append(np.random.uniform(r+5,re1_max))\n",
    "    re1__ = np.array(re1__)\n",
    "    re1__ = np.where(re1__<ri1__+5,ri1__+5,re1__)\n",
    "    re1 = np.concatenate((re1,re1_,re1__),0)\n",
    "    ri1 = np.concatenate((ri1,ri1_,ri1__),0)\n",
    "    re2 = np.concatenate((re2,re2_,re2__),0)\n",
    "    ri2 = np.concatenate((ri2,ri2_,ri2__),0)\n",
    "    \n",
    "    # We also generate densities (d1 and d2) uniformly at random from the range [1, 12].\n",
    "    \n",
    "    d1 = np.random.uniform(d_min,d_max,(re1.shape[0],1))\n",
    "    d2 = np.random.uniform(d_min,d_max,(re1.shape[0],1))\n",
    "    \n",
    "    # Calculate the surface area and mass of each cylinder using their radii and densities\n",
    "    s1=np.pi*(re1**2-ri1**2)\n",
    "    s2=np.pi*(re2**2-ri2**2)\n",
    "    m1 = s1*d1/1000 \n",
    "    m2 = s2*d2/1000\n",
    "    \n",
    "    # Generate the mass of the cube (m_cube) uniformly at random from the range [min(m1+m2), max(m1+m2)]\n",
    "    m_cube = np.random.uniform(min(m1+m2),max(m1+m2),(re1.shape[0],1))\n",
    "    \n",
    "    # Calculate the distances x and y while maintaining the equilibrium equation\n",
    "    x = np.random.uniform(1,99,(re1.shape[0],1))\n",
    "    y = (m1+m2)*x/m_cube\n",
    "    xy = x+y\n",
    "    x = x*100/xy\n",
    "    y = y*100/xy \n",
    "\n",
    "    hyper_params = np.concatenate((x,y,m_cube),axis=1)\n",
    "    optim_results = np.concatenate((ri1,re1,ri2,re2,d1,d2),axis=1)\n",
    "    return hyper_params, optim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n,return_hparams=False):\n",
    "    hyper_params, optim_results = generate(n)\n",
    "    dataset_array = np.concatenate((hyper_params,optim_results),axis=1)\n",
    "    dataset_df = pd.DataFrame(dataset_array,columns=['x','y','m_cube','rayon_i_1','rayon_e_1','rayon_i_2','rayon_e_2','densite_1','densite_2'])\n",
    "    s1=np.pi*(dataset_df.rayon_e_1**2-dataset_df.rayon_i_1**2)\n",
    "    s2=np.pi*(dataset_df.rayon_e_2**2-dataset_df.rayon_i_2**2)\n",
    "    m1 = s1*dataset_df.densite_1/1000 \n",
    "    m2 = s2*dataset_df.densite_2/1000\n",
    "    dataset_df['masse_generee']=m1+m2\n",
    "    dataset_df['equilibre']=((m1+m2)*dataset_df.x-dataset_df.m_cube*dataset_df.y)**2\n",
    "    if return_hparams:\n",
    "        return dataset_df,hyper_params\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:20<00:00,  6.98s/it]\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(os.path.abspath('..'),\"Clean Notebooks/src/dataset/meta\")\n",
    "stages = ['train', 'val', 'test']\n",
    "stage_sizes = [20000, 5000, 1000]\n",
    "\n",
    "for i in tqdm(range(len(stages))):\n",
    "    stage = stages[i]\n",
    "    dataset_path = os.path.join(save_path, stage)\n",
    "    \n",
    "    # Create the directories if they don't exist\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    \n",
    "    # dataframe\n",
    "    dataset, h = generate_dataset(stage_sizes[i], True)\n",
    "    \n",
    "    # cylinders\n",
    "    int_cylinder, ext_cylinder = [], []\n",
    "    for _, row in dataset.iterrows():\n",
    "        int_cylinder.append(get_c_points(row['rayon_i_2'], row['rayon_e_2'], 30))\n",
    "        ext_cylinder.append(get_c_points(row['rayon_i_1'], row['rayon_e_1'], 30))\n",
    "    int_cylinder = np.array(int_cylinder)\n",
    "    ext_cylinder = np.array(ext_cylinder)\n",
    "    \n",
    "    # densities\n",
    "    ext_density, int_density = [], []\n",
    "    for _, row in dataset.iterrows():\n",
    "        int_density.append(get_d_points(row['densite_2'], 30))\n",
    "        ext_density.append(get_d_points(row['densite_1'], 30))\n",
    "    ext_density = np.array(ext_density)\n",
    "    int_density = np.array(int_density)\n",
    "    \n",
    "    # save data\n",
    "    dataset.to_csv(os.path.join(dataset_path, 'dataset'))\n",
    "    np.save(os.path.join(dataset_path, 'int_cylinder'), int_cylinder)\n",
    "    np.save(os.path.join(dataset_path, 'ext_cylinder'), ext_cylinder)\n",
    "    np.save(os.path.join(dataset_path, 'int_density'), int_density)\n",
    "    np.save(os.path.join(dataset_path, 'ext_density'), ext_density)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPVONy3caU/7bcls0Fs6KO+",
   "collapsed_sections": [
    "t9nswTThvVj0",
    "NX9aXOVFcRmd",
    "xYlP-H9IdciI",
    "O27ePim-cJih",
    "HZsf7Tti35PT",
    "3zl_bzMB6e2T",
    "YpNOni3bKx52"
   ],
   "mount_file_id": "1_8TnqNCyL9G7TO0UHm-JST9ZX5EWp1Se",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
